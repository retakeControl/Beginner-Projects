#Using beautifulsoup to scrape multiple URLs and print as list.

#Step 1: Importing the necessary packages.
import requests
import csv
import time
from bs4 import BeautifulSoup

#Step 2: Consolidating required URLs from source website.
urls = [
    'https://www.ema.gov.sg/Licensees_Electricity_Generation_Company.aspx',
    'https://www.ema.gov.sg/licensees-electricity-importer.aspx', 
    'https://www.ema.gov.sg/Licensees_Electricity_Retailer.aspx', 
    'https://www.ema.gov.sg/Licensees_Electricity_Wholesaler.aspx',
    'https://www.ema.gov.sg/Licensees_Electricity_Market_Support_Services.aspx',
    'https://www.ema.gov.sg/Licensees_Electricity_Transmission_Company_Agent.aspx', 
    'https://www.ema.gov.sg/Licensees_Electricity_Market_Company.aspx', 
    'https://www.ema.gov.sg/Licensees_Gas_Transporter.aspx', 
    'https://www.ema.gov.sg/Licensees_Gas_Transport_Agent.aspx', 
    'https://www.ema.gov.sg/Licensees_Gas_Shipper.aspx', 
    'https://www.ema.gov.sg/Licensees_Gas_Retailer.aspx',
    'https://www.ema.gov.sg/Licensees_Gas_Importer_LNG.aspx', 
    'https://www.ema.gov.sg/Licensees_Gas_Onshore_Receiving_Facility_Operator.aspx', 
    'https://www.ema.gov.sg/Licensees_Gas_LNG_Terminal_Operator.aspx'
]

#Initiate a for loop to run through all URLs listed above.
for url in urls:
    response = requests.get(url)
    soup = BeautifulSoup(response.content, "html.parser")
    intlinks = soup.find_all('a', {'class':'intlink'})
    
#Step 3: Casting the output as strings in a list.   
    data = []
    for intlink in intlinks:
        company_name = intlink.text.strip()

#Step 4: Printing the output      
        print(f'Company name: {company_name}')
        
    # Append the company name and URL to the list
    data.append([company_name])
    

#Step 4: Exporting the output

# Write the data to a CSV file
with open('companies.csv', 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(['Company Name'])
    writer.writerows(data)
